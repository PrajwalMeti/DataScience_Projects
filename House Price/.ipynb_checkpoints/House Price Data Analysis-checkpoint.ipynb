{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14df5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is a libray which we can perform the analysis and having lacks of helper functions \n",
    "# Table in spread sheet or excel is called data fream in the Python \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df = pd.read_csv('house_price_data.csv')\n",
    "hp_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b723f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.shape # Returns to  get the number of rows and columns in the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = hp_df.groupby(['MSZoning']).mean('SalePrice')\n",
    "plt.boxplot(hp_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aabfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.shape[1] # to get the columns in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to Access all the Columns in data frame\n",
    "hp_df.columns  # Returns the Name of the columns from the Data Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901486ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Access the particualar columns\n",
    "hp_df['LotFrontage']  # Series[Equavlant to a column] to access the single column\n",
    "hp_df[['MSZoning','LotArea','Street']] #To Access the multiple columns [ we have to pass like the list ] (Using the list) \n",
    "hp_df[['MSZoning','LotArea','Street']] # Access the multiple objects from the data frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbe7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.iloc[3:8,4:10]  # To access the particluar value [3:8] is the number of rows we are access from and to \n",
    "                      # [4:10] To access the number of columns from and to \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa375031",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.iloc[:3,:3]   # .iloc is used for the indexing in the Data Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df[hp_df['SalePrice'] > 200000]   # Filter on the Data Frame  it will returns the all the recoreds where sales price greater than 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 2 variables in data science 1)Coninous variables -->  Real values or number \n",
    "# 2) Categorical Variables--> Enum fields in the BAAN \n",
    "hp_df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['MSZoning'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ec804",
   "metadata": {},
   "outputs": [],
   "source": [
    "(hp_df['MSZoning'].value_counts())['FV']  # returns the all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7902226",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['SalePrice'].describe() # Returns the Descriptve Statistics of continious variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['SalePrice'].describe()['count'] # Returns the count in the statstics of the continious variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.dtypes  # To know the data types of all the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0827d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df[['SalePrice','MSZoning']].dtypes   # To indentify the particular data type of the columns \n",
    "hp_df['SalePrice'].dtypes\n",
    "hp_df['MSZoning'].dtypes   # O Stnads for Objects \n",
    "#when ever the Data type is O or objects than it is a catagorical Objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['MSSubClass'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the continious variables into catagorical variables and assign it to back to the Data Frame\n",
    "hp_df['MSSubClass']=hp_df['MSSubClass'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['MSSubClass'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter of the tYPE 2) Categorical Variables in the Data Frame \n",
    "hp_df[hp_df['MSZoning'] == 'RM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3febc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['MSZoning'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.sort_values(by = 'SalePrice',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all the sum of the missing values in the Data Frame of induival columns  \n",
    "hp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be63ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.isnull().sum(axis = 1) # get the missing values count in each rows Axis = 1 is done by rows values axis = 0 done by column wise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values using the .fillna and update that with the mean of the lot Frontage and assigned into the Data Frame\n",
    "\n",
    "hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88402561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54258d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the all the missing values in the particular column\n",
    "hp_df['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['LotFrontage'].fillna('Prajwal',inplace = True) # it was replaceing the all the empty values with the Prajwal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['LotFrontage'].isnull().sum() # To Calculate the all the data of the columns having null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df = hp_df.drop(columns = 'LotFrontage') # This is used to Delete a column from the Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875fc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeba63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implimentation of apply functions \n",
    "def get_centure(year):\n",
    "    if year > 2000:\n",
    "        return '21st Century'\n",
    "    elif year < 2000:\n",
    "        return '20th Century'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1035f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['Century'] = hp_df['YearBuilt'].apply(get_centure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b431ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logorithum Calculations \n",
    "hp_df['LotArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['LotArea'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79de641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sale Price & Lot Area # Coefficiant co realtaion function is the function relation b/n 2 continues objects in the Data Frame \n",
    "# numpy self defined functions --> np.long To find the logarithum values \n",
    "#                              --> np.corrcoef\n",
    "np.corrcoef(hp_df['SalePrice'],hp_df['LotArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(hp_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(hp_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e430feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(hp_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13175cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hp_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f99f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python functions that takes the columns (names ) from hp_df and retunrs a list of outlier values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48cf25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(hp_df['Utilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85169d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(hp_df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ffc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77463ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.groupby('MSZoning').mean('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33528169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python functions that takes the columns (names) from hp_df and retunrs a list of outlier values\n",
    "\n",
    "# Important Question in Interview \n",
    "def Calculate_outliers(col):\n",
    "    q1 = (col.describe())['25%']\n",
    "    q3 = (col.describe())['75%']\n",
    "    iqr = q3 - q1\n",
    "    hvo,lvo = [],[]\n",
    "    for value in col:\n",
    "        if value > q3 + (1.5* (iqr)):\n",
    "            hvo.append(value)\n",
    "        elif value < q1 - (1.5*(iqr)):\n",
    "            lvo.append(value)\n",
    "    total = [hvo,lvo]\n",
    "    return total \n",
    "Calculate_outliers(hp_df['LotArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manohar's Method to calculate-->\n",
    "#the write a python functions that takes the columns (names) from hp_df and retunrs a list of outlier values\n",
    "# Important Question in Interview \n",
    "\n",
    "def get_outliers(col):\n",
    "    q1 = (hp_df[col].describe())['25%']\n",
    "    q3 = (hp_df[col].describe())['75%']\n",
    "    iqr = q3 - q1 \n",
    "    return [val for val in hp_df[col] if val > q3 + (1.5*iqr)],[val for val in hp_df[col] if val < q1 - (1.5*iqr)]\n",
    "get_outliers('LotArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cf082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by using the Pandas   \n",
    "hp_df.groupby('MSZoning').mean('SalePrice')      # To Access for all the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ec481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to use the Group by for the Catagorical variables \n",
    "hp_df[hp_df['MSZoning'] == 'RL']['SalePrice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by using the Pandas   \n",
    "hp_df.groupby('MSZoning').mean('SalePrice')['SalePrice']      # To Access for all the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.drop(columns = ['MSSubClass','MSZoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c467aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "     Chi-Square Test :--> It is Hypothysis Test --> To Test the Corelation Betweeen two Catagorical Varaible \n",
    "    Steps for Hypothysis\n",
    "    \n",
    "    1.  Null Hypothysis :No Corelation exist between the two Variables .\n",
    "    2. Alternate Hypothysis : Corelation Exist.\n",
    "    3. Confidence Level =  0.95  and Significance Level  = 1- 0.95 = 0.05\n",
    "    4. Collect the evidence \n",
    "    5. Calculate the chi -2 test stastics & P -value \n",
    "    6. Conclude : if p -values  from step(5) < significance level (0.05 ), Reject H0,\n",
    "                  if p -values from steup(5) > Significance level (0.05), Fail to Reject H0,\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49305dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Date 26/11/2023 ****************************************************************************\n",
    "# Chi-Squaire and Anova \n",
    "# 1. Chi-squair Test \n",
    "\n",
    "\"\"\" \n",
    "    Corelation check between MSZoing and LotShape (From hp_df) Dataframe\n",
    "    \n",
    "    Chi-Square Test :--> It is Hypothysis Test --> To Test the Corelation Betweeen two Catagorical Varaible \n",
    "    \n",
    "    Steps for Hypothysis.\n",
    "    1. Null Hypothysis (H0):No Corelation exist between the two Variables .\n",
    "    2. Alternate Hypothysis (HA) : it is opposite of Hypothysis\n",
    "    3. Set up the Confidence level \n",
    "        Confidence level = 0.95 , Significance Level = 1 - 0.95 = 0.05 \n",
    "    4. Collect the Evidence \n",
    "    5. Calculate the chi-2 Test Statistics & P- Values \n",
    "    6. Conclude:  if p -values  from step(5) < significance level (0.05 ), Reject H0, Corelated\n",
    "                  if p -values from steup(5) > Significance level (0.05), Fail to Reject H0, Not Corelated  \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-2 Test we will use for the 2 catogorical variables \n",
    "# Corelation check between MSZoing and LotShape (From hp_df) Dataframe\n",
    "# for this we have to import the helper function from scipy library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scipy.stats \n",
    "from scipy.stats import chi2_contingency\n",
    "# It was used to get the Observed Table of 2 Catogorical dataframe \n",
    "observed_table = pd.crosstab(hp_df['MSZoning'],hp_df['LotShape'])  \n",
    "chi2_contingency(observed_table)\n",
    "p_value =chi2_contingency(observed_table)[1]\n",
    "p_value # 0.00000000000000000001359 < 0.05   Reject the Null Hypothysis, There for these 2 variables are Correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689aaf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree of Freedom (DOF)\n",
    "# For N Number of stundents N-1 students having the Freedom to choose the Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002be700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSZoning --> Catogorical Variable \n",
    "# Write a logic to check corelation between MSZoning and Other Catogorical Variables From hp_df  \n",
    "# My Solution \n",
    "Catogorical_Variables = hp_df.select_dtypes(include=\"object\")\n",
    "List_of_Catogorical  =Catogorical_Variables.columns\n",
    "def all_catogrical_corellated_varaibles(List_of_Catogorical):\n",
    "    correlated_varaibles = []\n",
    "    for each_variable in List_of_Catogorical:\n",
    "        observed_table = pd.crosstab(hp_df['MSZoning'],hp_df[each_variable])\n",
    "        chi2_contingency(observed_table)\n",
    "        p_value = chi2_contingency(observed_table)[1]\n",
    "        if p_value < 0.05:\n",
    "            correlated_varaibles.append(each_variable)\n",
    "    return correlated_varaibles\n",
    "all_catogrical_corellated_varaibles(List_of_Catogorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSZoning --> Catogorical Variable \n",
    "# Write a logic to check corelation between MSZoning and Other Catogorical Variables From hp_df  \n",
    "# Mentor Method --> Manohar Method \n",
    "cat_col = [col for col in hp_df.columns if hp_df[col].dtype == 'object']\n",
    "for col in cat_col:\n",
    "    observed_tables = pd.crosstab(hp_df['MSZoning'],hp_df[col])\n",
    "    if chi2_contingency(observed_tables)[1] < 0.05:\n",
    "        print(col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Between MZZooming( Catogorical Variable) & Sales Price \n",
    "hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0147d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "RL_list = hp_df[hp_df['MSZoning'] == 'RL']['SalePrice']\n",
    "RM_list = hp_df[hp_df['MSZoning'] == 'RM']['SalePrice']\n",
    "FV_list = hp_df[hp_df['MSZoning'] == 'FV']['SalePrice']\n",
    "RH_list = hp_df[hp_df['MSZoning'] == 'R']['SalePrice']\n",
    "C_all_list = hp_df[hp_df['MSZoning'] == 'C (all)']['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_oneway(RL_list,RM_list,FV_list,RH_list,C_all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbdc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Between Groups / Variance within Groups \n",
    "hp_df['SalePrice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b99c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_mean = hp_df[hp_df['MSZoning'] == 'RL']['SalePrice'].mean()  # RL \n",
    "RM_list = hp_df[hp_df['MSZoning'] == 'RM']['SalePrice'].mean()  # RM \n",
    "FV_list = hp_df[hp_df['MSZoning'] == 'FV']['SalePrice'].mean()  # FV\n",
    "RH_list = hp_df[hp_df['MSZoning'] == 'RH']['SalePrice'].mean()  # RH \n",
    "C_all_list = hp_df[hp_df['MSZoning'] == 'C (all)']['SalePrice'].mean() # CAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018eaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varuabce  Between the Groups \n",
    "print((hp_df['SalePrice'].mean() - hp_df[hp_df['MSZoning'] == 'RL']['SalePrice'].mean())** 2 + \n",
    "((hp_df['SalePrice'].mean() - hp_df[hp_df['MSZoning'] == 'RM']['SalePrice'].mean())** 2  +\n",
    "(hp_df['SalePrice'].mean() - hp_df[hp_df['MSZoning'] == 'FV']['SalePrice'].mean())** 2  +\n",
    "(hp_df['SalePrice'].mean() - hp_df[hp_df['MSZoning'] == 'RH']['SalePrice'].mean())** 2 +\n",
    "(hp_df['SalePrice'].mean() - hp_df[hp_df['MSZoning'] == 'C (all)']['SalePrice'].mean())** 2))\n",
    "x =  180921.19589041095 /17934657719.26021\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15106e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAPF That takes a categorical variable (from hp_df) and check for the correlation with salePrice.\n",
    "#sample_input = 'MSZoning'\n",
    "#sample_output = 'Correlated'\n",
    "def annva(col):\n",
    "    categories = list(hp_df[col].value_counts().index)\n",
    "    p_value = f_oneway(*[hp_df[hp_df[col] == cat]['SalePrice'] for cat in categories])[1]\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        return 'Correlated'\n",
    "    else:\n",
    "        return 'Not Correlated'\n",
    "annva('MSZoning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c9a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238019d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAPF That takes a input from the and check with the output sales price and return correlated or not \n",
    "\n",
    "def anova(col):\n",
    "    Correlated = []\n",
    "    x = hp_df.select_dtypes(include=\"object\")\n",
    "    for columns in x:\n",
    "        categories = list(hp_df[columns].value_counts().index)\n",
    "        p_value = f_oneway(*[hp_df[hp_df[col] == cat]['SalePrice'] for cat in categories])[1]\n",
    "\n",
    "        Correlated.append(p_value)\n",
    "    return Correlated\n",
    "z = anova(x)\n",
    "list(zip(x,z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20eddff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAPF That takes a input from the and check with the output sales price and return correlated or not\n",
    "col = hp_df.select_dtypes(include=\"object\")\n",
    "col = col.columns\n",
    "def anova(col):\n",
    "    Correlated = []\n",
    "    for columns in col:\n",
    "        categories = list(hp_df[columns].value_counts().index)\n",
    "        p_value = f_oneway(*[hp_df[hp_df[columns] == cat]['SalePrice'] for cat in categories])[1]\n",
    "        if p_value < 0.05:\n",
    "            Correlated.append('Correlated')\n",
    "        else:\n",
    "            Correlated.append('Not Correlated')\n",
    "    return Correlated\n",
    "anova(col)\n",
    "list(zip(col,anova(col)))\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec96a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a logic to Create a DataFrame 3 Columns \n",
    "MSZoning    NA Count 0     NA Count % \n",
    "MSSbuclass    100 \n",
    "LOt Frontage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prajju = pb.DataFrame(hp_df.columns,columns = )\n",
    "x = hp_df.columns\n",
    "Pr_df = pd.DataFrame(x,columns =['Description'])\n",
    "Pr_df = pd.DataFrame(hp_df.isnull().sum(axis = 0),columns = ['No of Missing values'])\n",
    "# Pr_df = \n",
    "Pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_null_values_in_each_column(No_of_rows,Null_values_in_each_column):\n",
    "    percentage = []\n",
    "    for i in x:\n",
    "        percentage.append((i/No_of_rows)* 100)\n",
    "    return percentage\n",
    "Percentage_each_column = percentage_of_null_values_in_each_column(hp_df.shape[0],Pr_df['No of Missing values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e20a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31-12-2023   # Learn about the Scaling 1.Standards Scalre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b403ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e241c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_df = pd.read_csv('house_price_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5af9b578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20714171],\n",
       "       [-0.09188637],\n",
       "       [ 0.07347998],\n",
       "       ...,\n",
       "       [-0.14781027],\n",
       "       [-0.08016039],\n",
       "       [-0.05811155]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Scalred We should not apply the Stnadard Scler \n",
    "# In Numpy array if you want to choose give the numpy to decide the array shapre  then give it as -1 \n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "std_scaled_values = std_scaler.fit_transform(np.array(hp_df['LotArea']).reshape(-1,1))\n",
    "std_scaled_values   # 0 = mean and the 1 Variance and standard deviation is 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "373524be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04663743534762722"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler_values = min_max_scaler.fit_transform(np.array(hp_df['LotArea']).reshape(-1,1))\n",
    "min_max_scaler_values.std()   # each Scaled Values between the 0 and 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72f46ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730865</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>RL</td>\n",
       "      <td>-0.208034</td>\n",
       "      <td>-0.207142</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-1.599111</td>\n",
       "      <td>0.138777</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.347273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.728492</td>\n",
       "      <td>-0.872563</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.409895</td>\n",
       "      <td>-0.091886</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-0.489110</td>\n",
       "      <td>-0.614439</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.007288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.726120</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>RL</td>\n",
       "      <td>-0.084449</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>0.990891</td>\n",
       "      <td>0.138777</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.536154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.723747</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>RL</td>\n",
       "      <td>-0.414011</td>\n",
       "      <td>-0.096897</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-1.599111</td>\n",
       "      <td>-1.367655</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>-0.515281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.721374</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.574676</td>\n",
       "      <td>0.375148</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>2.100892</td>\n",
       "      <td>0.138777</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.869843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1.721374</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>RL</td>\n",
       "      <td>-0.331620</td>\n",
       "      <td>-0.260560</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>0.620891</td>\n",
       "      <td>-0.614439</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-0.074560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1.723747</td>\n",
       "      <td>-0.872563</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.615871</td>\n",
       "      <td>0.266407</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-1.599111</td>\n",
       "      <td>1.645210</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.366161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1.726120</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>RL</td>\n",
       "      <td>-0.166839</td>\n",
       "      <td>-0.147810</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>4.953112</td>\n",
       "      <td>-0.489110</td>\n",
       "      <td>1.645210</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1.077611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1.728492</td>\n",
       "      <td>-0.872563</td>\n",
       "      <td>RL</td>\n",
       "      <td>-0.084449</td>\n",
       "      <td>-0.080160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-0.859110</td>\n",
       "      <td>1.645210</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-0.488523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1.730865</td>\n",
       "      <td>-0.872563</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.203918</td>\n",
       "      <td>-0.058112</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087688</td>\n",
       "      <td>-0.119110</td>\n",
       "      <td>0.138777</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-0.420841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  MSSubClass MSZoning  LotFrontage   LotArea Street Alley  \\\n",
       "0    -1.730865    0.073375       RL    -0.208034 -0.207142   Pave   NaN   \n",
       "1    -1.728492   -0.872563       RL     0.409895 -0.091886   Pave   NaN   \n",
       "2    -1.726120    0.073375       RL    -0.084449  0.073480   Pave   NaN   \n",
       "3    -1.723747    0.309859       RL    -0.414011 -0.096897   Pave   NaN   \n",
       "4    -1.721374    0.073375       RL     0.574676  0.375148   Pave   NaN   \n",
       "...        ...         ...      ...          ...       ...    ...   ...   \n",
       "1455  1.721374    0.073375       RL    -0.331620 -0.260560   Pave   NaN   \n",
       "1456  1.723747   -0.872563       RL     0.615871  0.266407   Pave   NaN   \n",
       "1457  1.726120    0.309859       RL    -0.166839 -0.147810   Pave   NaN   \n",
       "1458  1.728492   -0.872563       RL    -0.084449 -0.080160   Pave   NaN   \n",
       "1459  1.730865   -0.872563       RL     0.203918 -0.058112   Pave   NaN   \n",
       "\n",
       "     LotShape LandContour Utilities  ...  PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0         Reg         Lvl    AllPub  ... -0.068692    NaN    NaN         NaN   \n",
       "1         Reg         Lvl    AllPub  ... -0.068692    NaN    NaN         NaN   \n",
       "2         IR1         Lvl    AllPub  ... -0.068692    NaN    NaN         NaN   \n",
       "3         IR1         Lvl    AllPub  ... -0.068692    NaN    NaN         NaN   \n",
       "4         IR1         Lvl    AllPub  ... -0.068692    NaN    NaN         NaN   \n",
       "...       ...         ...       ...  ...       ...    ...    ...         ...   \n",
       "1455      Reg         Lvl    AllPub  ... -0.068692    NaN    NaN         NaN   \n",
       "1456      Reg         Lvl    AllPub  ... -0.068692    NaN  MnPrv         NaN   \n",
       "1457      Reg         Lvl    AllPub  ... -0.068692    NaN  GdPrv        Shed   \n",
       "1458      Reg         Lvl    AllPub  ... -0.068692    NaN    NaN         NaN   \n",
       "1459      Reg         Lvl    AllPub  ... -0.068692    NaN    NaN         NaN   \n",
       "\n",
       "       MiscVal    MoSold    YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0    -0.087688 -1.599111  0.138777        WD         Normal   0.347273  \n",
       "1    -0.087688 -0.489110 -0.614439        WD         Normal   0.007288  \n",
       "2    -0.087688  0.990891  0.138777        WD         Normal   0.536154  \n",
       "3    -0.087688 -1.599111 -1.367655        WD        Abnorml  -0.515281  \n",
       "4    -0.087688  2.100892  0.138777        WD         Normal   0.869843  \n",
       "...        ...       ...       ...       ...            ...        ...  \n",
       "1455 -0.087688  0.620891 -0.614439        WD         Normal  -0.074560  \n",
       "1456 -0.087688 -1.599111  1.645210        WD         Normal   0.366161  \n",
       "1457  4.953112 -0.489110  1.645210        WD         Normal   1.077611  \n",
       "1458 -0.087688 -0.859110  1.645210        WD         Normal  -0.488523  \n",
       "1459 -0.087688 -0.119110  0.138777        WD         Normal  -0.420841  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in hp_df.columns:\n",
    "    if hp_df[column].dtype == 'int64'or hp_df[column].dtype == 'float64':\n",
    "        hp_df[column] = std_scaler.fit_transform(np.array(hp_df[column]).reshape(-1,1))\n",
    "hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3339021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Catogorical Techniques there are 2 types of \n",
    "# Encoding Technique are there \n",
    "#    1. One-Hot Encoding \n",
    "#    2. Label Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2dcc159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSZoning\n",
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12644173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C (all)</th>\n",
       "      <th>FV</th>\n",
       "      <th>RH</th>\n",
       "      <th>RL</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      C (all)  FV  RH  RL  RM\n",
       "0           0   0   0   1   0\n",
       "1           0   0   0   1   0\n",
       "2           0   0   0   1   0\n",
       "3           0   0   0   1   0\n",
       "4           0   0   0   1   0\n",
       "...       ...  ..  ..  ..  ..\n",
       "1455        0   0   0   1   0\n",
       "1456        0   0   0   1   0\n",
       "1457        0   0   0   1   0\n",
       "1458        0   0   0   1   0\n",
       "1459        0   0   0   1   0\n",
       "\n",
       "[1460 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe_mszoning = pd.get_dummies(hp_df['MSZoning'])    # One-hot Encoding \n",
    "\n",
    "oe_mszoning.replace({True:1,False:0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c91d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw-back of One-hot Encoading \n",
    "# the thing is if 1000 unique values count is availabel in the Data set then we have to perfrom the 1000-1 = 999 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61812dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RL', 'RH', 'FV', 'C (all)'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd Encoading \n",
    "# Label Encoading \n",
    "le = LabelEncoder()\n",
    "le.fit_transform(hp_df['MSZoning'])\n",
    "le.inverse_transform([3,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02326905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotencod = OneHotEncoder()\n",
    "oneHotencod.fit_transform(np.array(hp_df['MSZoning']).reshape(-1,1))\n",
    "oneHotencod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fa2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Co-linearity --> Co-relation betweent the input amoung the models "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
